window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "spectraxai", "modulename": "spectraxai", "type": "module", "doc": "<h1 id=\"welcome-to-the-spectraxai-library\">Welcome to the SpectraXAI library.</h1>\n\n<p>A library to easily develop XAI models for spectral datasets.</p>\n\n<h2 id=\"features\">Features</h2>\n\n<ul>\n<li>Easy setup with pip</li>\n<li>Documented using pdoc following the numpydoc style</li>\n</ul>\n\n<h1 id=\"quickstart\">Quickstart</h1>\n\n<p>As an example, we quickly develop a PLS model for a dataset and\nplot the feature importance.</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"sd\">&quot;&quot;&quot;</span>\n<span class=\"sd\">A small `spectraxai` example.</span>\n<span class=\"sd\">&quot;&quot;&quot;</span>\n\n<span class=\"c1\"># Load the dataset</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.data</span> <span class=\"kn\">import</span> <span class=\"n\">load_GR_SSL</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">load_GR_SSL</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Apply SG1 on the spectra and train &amp; test a PLS model</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.models</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span><span class=\"p\">,</span> <span class=\"n\">StandardModel</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.spectra</span> <span class=\"kn\">import</span> <span class=\"n\">SpectralPreprocessing</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.dataset</span> <span class=\"kn\">import</span> <span class=\"n\">DatasetSplit</span>\n\n<span class=\"n\">idx_trn</span><span class=\"p\">,</span> <span class=\"n\">idx_tst</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">DatasetSplit</span><span class=\"o\">.</span><span class=\"n\">KENNARD_STONE</span><span class=\"p\">,</span> <span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">pls</span> <span class=\"o\">=</span> <span class=\"n\">StandardModel</span><span class=\"p\">(</span><span class=\"n\">Model</span><span class=\"o\">.</span><span class=\"n\">PLS</span><span class=\"p\">)</span>\n\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">pls</span><span class=\"o\">.</span><span class=\"n\">fit_and_predict</span><span class=\"p\">(</span>\n    <span class=\"n\">dataset</span><span class=\"p\">,</span>\n    <span class=\"n\">preprocess</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">SpectralPreprocessing</span><span class=\"o\">.</span><span class=\"n\">SG1</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">&quot;window_length&quot;</span><span class=\"p\">:</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"s2\">&quot;polyorder&quot;</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">}),</span>\n    <span class=\"n\">idx_trn</span><span class=\"o\">=</span><span class=\"n\">idx_trn</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Plot the feature importance</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.explain</span> <span class=\"kn\">import</span> <span class=\"n\">PostHocAnalysis</span>\n\n<span class=\"n\">xai</span> <span class=\"o\">=</span> <span class=\"n\">PostHocAnalysis</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">xai</span><span class=\"o\">.</span><span class=\"n\">bar_plot_importance</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"s2\">&quot;feature_importance&quot;</span><span class=\"p\">])</span>\n</code></pre></div>\n"}, {"fullname": "spectraxai.data", "modulename": "spectraxai.data", "type": "module", "doc": "<p>The module <code>spectraxai.data</code> loads sample datasets.</p>\n\n<p>Currently the only dataset packaged and supplied with this library is the Greek\npart of the GEO-CRADLE SSL, see <code>spectraxai.data.load_GR_SSL</code>.</p>\n"}, {"fullname": "spectraxai.data.load_GR_SSL", "modulename": "spectraxai.data", "qualname": "load_GR_SSL", "type": "function", "doc": "<p>Load the GEO-CRADLE SSL for the Greek soils.</p>\n\n<p>This dataset is part of the GEO-CRADLE SSL, which may be found\n<a href=\"http://datahub.geocradle.eu/dataset/regional-soil-spectral-library\">here</a>.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>subsampling</strong> (<code>int</code>):\nThe spectral subsampling to perform; each data point corresponds to 1nm.\nDefaults to 20, i.e. 20 nm.</li>\n<li><strong>properties</strong> (<code>list</code> [<code>str</code>]):\nA list of strings containing the property names.\nDefaults to soil organic matter.</li>\n</ul>\n", "signature": "(subsampling=20, properties=['OM'])", "funcdef": "def"}, {"fullname": "spectraxai.dataset", "modulename": "spectraxai.dataset", "type": "module", "doc": "<p>The module <code>spectraxai.dataset</code> includes classes and operations on datasets.</p>\n\n<p>This module defines the class <code>Dataset</code> which ought to be used to handle all\nnecessary dataset transformations including scaling, spectral pre-processing,\nand splitting. The classes defined in <code>spectraxai.models</code> and\n<code>spectraxai.explain</code> generally expect as inputs a <code>Dataset</code> object to operate\non.</p>\n"}, {"fullname": "spectraxai.dataset.Scale", "modulename": "spectraxai.dataset", "qualname": "Scale", "type": "class", "doc": "<p>Scaling of an input feature (or of the output).</p>\n\n<p>Uses the <code>sklearn.preprocessing</code> library under the hood.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.dataset.Scale.STANDARD", "modulename": "spectraxai.dataset", "qualname": "Scale.STANDARD", "type": "variable", "doc": "<p>Standard scaling, i.e. removing the mean and scaling to unit variance</p>\n", "default_value": " = standard"}, {"fullname": "spectraxai.dataset.Scale.MINMAX", "modulename": "spectraxai.dataset", "qualname": "Scale.MINMAX", "type": "variable", "doc": "<p>Scale and translate so that the range is between zero and one</p>\n", "default_value": " = min-max"}, {"fullname": "spectraxai.dataset.Scale.apply", "modulename": "spectraxai.dataset", "qualname": "Scale.apply", "type": "function", "doc": "<p>Apply a method to scale a given array.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D matrix to be scaled</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method to use for scaling</li>\n<li><strong>set_params</strong> (dict, optional):\nA dictionary of parameters defined in the corresponding\n<code>sklearn.preprocessing</code> class</li>\n<li><strong>set_attributes</strong> (dict, optional):\nA dictionary of the attributes defined in the corresponding\n<code>sklearn.preprocessing</code> class</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>X</strong> (<code>np.ndarray</code>):\nThe scaled matrix</li>\n<li><strong>scale_params</strong> (dict):\nA dictionary of parameters defined in the corresponding\n<code>sklearn.preprocessing</code> class. Returned only if set_params\nwas not passed.</li>\n<li><strong>scale_attributes</strong> (dict):\nA dictionary of the attributes defined in the corresponding\n<code>sklearn.preprocessing</code> class. Returned only if set_attributes\nwas not passed.</li>\n</ul>\n", "signature": "(\n    X: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: Dict = {},\n    set_attributes: Dict = {}\n) -> Tuple[numpy.ndarray, Dict, Dict]", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Scale.inverse", "modulename": "spectraxai.dataset", "qualname": "Scale.inverse", "type": "function", "doc": "<p>Apply a method to un-scale a given array.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D matrix to be un-scaled</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method used to scale the matrix</li>\n<li><strong>set_params</strong> (dict):\nA dictionary of parameters defined in the corresponding\n<code>sklearn.preprocessing</code> class</li>\n<li><strong>set_attributes</strong> (dict):\nA dictionary of the attributes defined in the corresponding\n<code>sklearn.preprocessing</code> class</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: The un-scaled matrix</li>\n</ul>\n", "signature": "(\n    X: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: Dict = {},\n    set_attributes: Dict = {}\n) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "spectraxai.dataset.DatasetSplit", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit", "type": "class", "doc": "<p>Types of dataset split supported by the <code>Dataset</code> class.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.dataset.DatasetSplit.RANDOM", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.RANDOM", "type": "variable", "doc": "<p></p>\n", "default_value": " = random"}, {"fullname": "spectraxai.dataset.DatasetSplit.KENNARD_STONE", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.KENNARD_STONE", "type": "variable", "doc": "<p></p>\n", "default_value": " = Kennard-Stone"}, {"fullname": "spectraxai.dataset.DatasetSplit.CLHS", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.CLHS", "type": "variable", "doc": "<p></p>\n", "default_value": " = clhs"}, {"fullname": "spectraxai.dataset.DatasetSplit.CROSS_VALIDATION", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.CROSS_VALIDATION", "type": "variable", "doc": "<p></p>\n", "default_value": " = cross-validation"}, {"fullname": "spectraxai.dataset.DatasetSplit.STRATIFIED", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.STRATIFIED", "type": "variable", "doc": "<p></p>\n", "default_value": " = stratified"}, {"fullname": "spectraxai.dataset.DataSplit", "modulename": "spectraxai.dataset", "qualname": "DataSplit", "type": "variable", "doc": "<p>A tuple representing a split for the <code>Dataset</code> into training and testing\nindices (in this order)</p>\n", "default_value": " = typing.Tuple[numpy.ndarray, numpy.ndarray]"}, {"fullname": "spectraxai.dataset.Dataset", "modulename": "spectraxai.dataset", "qualname": "Dataset", "type": "class", "doc": "<p>A general class to manage the dataset (i.e. input X and output Y).</p>\n\n<p>Use this class to pass your 2D spectral matrix and 1D or 2D output\nproperties. Supports methods for pre-processing X, scaling X and Y,\nsplitting the dataset, and more.</p>\n"}, {"fullname": "spectraxai.dataset.Dataset.__init__", "modulename": "spectraxai.dataset", "qualname": "Dataset.__init__", "type": "function", "doc": "<p>Create a new Dataset from input and output arrays.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code> or <code>pandas.DataFrame</code>):\nA 2D matrix of the spectra of size (<code>n_samples</code>, <code>n_features</code>)</li>\n<li><strong>Y</strong> (<code>numpy.ndarray</code> or <code>pandas.DataFrame</code> or <code>pandas.Series</code>):\nA 1D vector (<code>n_samples</code>,) or 2D matrix (<code>n_samples</code>, <code>n_outputs</code>)\nof the output property(ies). If 1D it will be implicitly converted\nto 2D.</li>\n<li><strong>X_names</strong> (<code>list[str]</code>, optional):\nA list of length <code>n_features</code> containing the names of the input\nfeatures. If missing, these will be autogenerated as X1, X2, etc.</li>\n<li><strong>Y_names</strong> (<code>list[str]</code>, optional):\nA list of length <code>n_outputs</code> containing the names of the output\nproperties. When using a single output property pass a list of\nsize 1. If missing, these will be autogenerated as Y1, Y2, etc.</li>\n</ul>\n", "signature": "(\n    self,\n    X: numpy.ndarray,\n    Y: numpy.ndarray,\n    X_names: List[str] = [],\n    Y_names: List[str] = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.n_samples", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_samples", "type": "variable", "doc": "<p>Number of samples in the dataset</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.n_features", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_features", "type": "variable", "doc": "<p>Number of features in the dataset's input</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.n_outputs", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_outputs", "type": "variable", "doc": "<p>Number of outputs in the dataset's output</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.X", "modulename": "spectraxai.dataset", "qualname": "Dataset.X", "type": "variable", "doc": "<p>The spectral data of size (<code>n_samples</code>, <code>n_features</code>)</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.dataset.Dataset.Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.Y", "type": "variable", "doc": "<p>The output properties of size (<code>n_samples</code>, <code>n_outputs</code>)</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.dataset.Dataset.X_names", "modulename": "spectraxai.dataset", "qualname": "Dataset.X_names", "type": "variable", "doc": "<p>The names of the input features of size (<code>n_features</code>)</p>\n", "annotation": ": List[str]"}, {"fullname": "spectraxai.dataset.Dataset.Y_names", "modulename": "spectraxai.dataset", "qualname": "Dataset.Y_names", "type": "variable", "doc": "<p>The names of the output properties of size (<code>n_outputs</code>)</p>\n", "annotation": ": List[str]"}, {"fullname": "spectraxai.dataset.Dataset.train_test_split", "modulename": "spectraxai.dataset", "qualname": "Dataset.train_test_split", "type": "function", "doc": "<p>Split dataset with passed split method to train and test.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>split</strong> (<code>DatasetSplit</code>):\nThe method used to split the dataset</li>\n<li><strong>opt</strong> (<code>Number</code>):\nA float number (between 0 and 1) indicating the percentage of the\ntraining dataset for Random and Kennard\u2013Stone split. A natural number\nfor Cross Validation and Stratified split.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>DataSplit</code></strong>: The idx_trn, idx_tst tuple. Use e.g. X[idx_trn], Y[idx_trn] to get the\ntraining dataset.</li>\n</ul>\n", "signature": "(\n    self,\n    split: spectraxai.dataset.DatasetSplit,\n    opt: numbers.Number\n) -> Tuple[numpy.ndarray, numpy.ndarray]", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.train_test_split_explicit", "modulename": "spectraxai.dataset", "qualname": "Dataset.train_test_split_explicit", "type": "function", "doc": "<p>Split dataset to train and test from pre-selected by the user indices.</p>\n\n<p>This is useful in cases where one has the set containing the training\nindices of a dataset and wants to get the complement of the training set to\nobtain the test set.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>trn</strong> (<code>np.ndarray</code>, optional):\nContains the indices of the training samples</li>\n<li><strong>tst</strong> (<code>np.ndarray</code>, optional):\nContains the indices of the testing samples</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>DataSplit</code></strong>: The idx_trn, idx_tst tuple</li>\n</ul>\n", "signature": "(\n    self,\n    trn: numpy.ndarray = array([], dtype=float64),\n    tst: numpy.ndarray = array([], dtype=float64)\n) -> Tuple[numpy.ndarray, numpy.ndarray]", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.subset", "modulename": "spectraxai.dataset", "qualname": "Dataset.subset", "type": "function", "doc": "<p>Subset the dataset using passed indices.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>idx</strong> (np.ndarray):\nThe indices to subset by</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A new Dataset populated by the passed indices</li>\n</ul>\n", "signature": "(self, idx: numpy.ndarray) -> spectraxai.dataset.Dataset", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.preprocess", "modulename": "spectraxai.dataset", "qualname": "Dataset.preprocess", "type": "function", "doc": "<p>Preprocess dataset by method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>spectraxai.spectra.SpectralPreprocessingSequence</code>):\nThe method for the preprocess.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A new Dataset object, where X contains the preprocessed spectra.</li>\n</ul>\n", "signature": "(\n    self,\n    method: Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]\n) -> spectraxai.dataset.Dataset", "funcdef": "def"}, {"fullname": "spectraxai.explain", "modulename": "spectraxai.explain", "type": "module", "doc": "<p>The module <code>spectraxai.explain</code> supports the interpretability analysis.</p>\n\n<p>This module defines the class <code>PreHocAnalysis</code> to operate only on a given\n<code>spectraxai.dataset.Dataset</code> and generate some insights solely from the data, as\nwell as a <code>PostHocAnalysis</code> to operate on a <code>spectraxai.models.StandardModel</code>\nwhich has been trained on a given <code>spectraxai.dataset.Dataset</code>.</p>\n"}, {"fullname": "spectraxai.explain.FeatureRanking", "modulename": "spectraxai.explain", "qualname": "FeatureRanking", "type": "class", "doc": "<p>Types of methods for calculating feature ranking.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.explain.FeatureRanking.CORR", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.CORR", "type": "variable", "doc": "<p></p>\n", "default_value": " = Pearson's correlation"}, {"fullname": "spectraxai.explain.FeatureRanking.MI", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.MI", "type": "variable", "doc": "<p></p>\n", "default_value": " = Mutual information"}, {"fullname": "spectraxai.explain.FeatureRanking.F_STATISTIC", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.F_STATISTIC", "type": "variable", "doc": "<p></p>\n", "default_value": " = F-statistic"}, {"fullname": "spectraxai.explain.PreHocAnalysis", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis", "type": "class", "doc": "<p>A class to provide methods for pre-hoc explainability analysis.</p>\n", "bases": "_Explain"}, {"fullname": "spectraxai.explain.PreHocAnalysis.feature_importance", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.feature_importance", "type": "function", "doc": "<p>Calculate feature importance between the input features and the output(s).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>FeatureRanking</code>):\nThe method to calculate the feature importance.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: The feature importance according to the selected method, which is a 2-D\nnp.array containing the ranking for each output property of size\n(<code>spectraxai.dataset.Dataset.n_outputs</code>,\n<code>spectraxai.dataset.Dataset.n_features</code>)</li>\n</ul>\n", "signature": "(self, method: spectraxai.explain.FeatureRanking) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.correlogram", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.correlogram", "type": "function", "doc": "<p>Plot a correlogram between the most important inputs and the output(s).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>top</strong> (<code>int</code>, optional):\nThe number of most important features to consider. Defaults to 5.</li>\n<li><strong>method</strong> (<code>FeatureRanking</code>, optional):\nThe method to calculate the feature importance.\nDefaults to FeatureRanking.CORR.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    top: int = 5,\n    method: spectraxai.explain.FeatureRanking = Pearson's correlation\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.bar_plot_importance", "type": "function", "doc": "<p>Plot a bar plot of feature ranking.</p>\n\n<p>The feature ranking is calculated between the input features and the output(s)\naccording to the method specified.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>FeatureRanking</code>, optional):\nThe method to calculate the feature importance.\nDefaults to FeatureRanking.CORR.</li>\n<li><strong>ax</strong> (Array of <code>plt.Axes</code>, optional):\nThe axes on where to draw the bar plot (for one or more output variables)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.explain.FeatureRanking = Pearson's correlation,\n    ax: Union[matplotlib.axes._axes.Axes, ForwardRef('np.ndarray[plt.Axes]')] = None\n)", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.mean_spectrum", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.mean_spectrum", "type": "function", "doc": "<p>Plot mean spectrum $\\pm$ sd of the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ax</strong> (<code>plt.Axes</code>, optional):\nAn optional matplotlib axes to plot into. Defaults to None,\nin which case a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(self, ax=None) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.mean_spectrum_by_range", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.mean_spectrum_by_range", "type": "function", "doc": "<p>Plot the mean spectrum (across all samples) per output range.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_ranges</strong> (List[np.array]):\nA list of length <code>spectraxai.dataset.n_outputs</code> containing the ranges to\ncalculate the mean spectrum wrapped in an np.array. For example,\nnp.array([0, 1, 5]) means calculate the means from [0, 1) and [1, 5].</li>\n<li><strong>preprocesses</strong> (<code>List[spectraxai.spectra.SpectralPreprocessing]</code>, optional):\nAn optional list of preprocessing techniques to plot simultaneously on the\nsame figure. If omitted, it only plots the spectra of the passed dataset.</li>\n<li><strong>ylims</strong> (List[List], optional):\nAn optional list of the ylim to use on each of the supplied preprocesses.\nIf preprocesses was omitted this can be a list of length 1 to act on the\ndataset's spectra.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    y_ranges: List,\n    preprocesses: List[spectraxai.spectra.SpectralPreprocessing] = [],\n    ylims: List = []\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis", "type": "class", "doc": "<p>A class to provide methods for post-hoc explainability analysis.</p>\n", "bases": "_Explain"}, {"fullname": "spectraxai.explain.PostHocAnalysis.bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.bar_plot_importance", "type": "function", "doc": "<p>Plot a bar plot of the feature importance.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>importance</strong> (<code>np.ndarray</code>):\nA numpy array of shape (<code>spectraxai.dataset.Dataset.n_features</code>,1)\ncontaining the importance of each feature</li>\n<li><strong>ax</strong> (<code>plt.Axes</code>, optional):\nAn optional matplotlib axes to plot into. Defaults to None,\nin which case a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    importance: numpy.ndarray,\n    ax: matplotlib.axes._axes.Axes = None\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.circular_bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.circular_bar_plot_importance", "type": "function", "doc": "<p>Plot a circular (spiral) bar plot of the feature importance.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>importance</strong> (<code>np.ndarray</code>):\nA numpy array of shape (<code>spectraxai.dataset.Dataset.n_features</code>,1)\ncontaining the importance of each feature</li>\n<li><strong>ax</strong> (`plt.Axes):\nAn optional matplotlib axes to plot into. Defaults to None,\nin which case a new figure is created.</li>\n<li><strong>top</strong> (<code>int</code>, optional):\nThe number of most important features to consider. Defaults to None, where\nall features all plotted.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    importance: numpy.ndarray,\n    ax: matplotlib.axes._axes.Axes = None,\n    top: int = None\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.bar_plot_permutation_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.bar_plot_permutation_importance", "type": "function", "doc": "<p>Create a bar plot using permutation feature importance.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (object):\nThe estimator that has already been fitted</li>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>, optional):\nAn optional dataset to calculate the scoring, which can be a hold-out set\ndifferent from the training data used to train the estimator. If this is\nnot supplied, <code>dataset</code> will be used instead.</li>\n<li><strong>ax</strong> (<code>plt.Axes</code>, optional):\nAn optional matplotlib axes to plot into. Defaults to None, in which\ncase a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    model,\n    dataset: spectraxai.dataset.Dataset = None,\n    ax: <function axes at 0x7f8cf1be51b0> = None\n)", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.sage_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.sage_importance", "type": "function", "doc": "<p>Calculate SAGE based importance.</p>\n\n<p>SAGE (Shapley Additive Global importancE) is a game-theoretic approach for\nunderstanding black-box machine learning models.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (object):\nThe estimator that has already been fitted</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: The feature importance according to SAGE</li>\n</ul>\n", "signature": "(self, model)", "funcdef": "def"}, {"fullname": "spectraxai.models", "modulename": "spectraxai.models", "type": "module", "doc": "<p>The module <code>spectraxai.models</code> includes classes and operations on ML models.</p>\n\n<p>This module defines the class <code>StandardModel</code> which should be used to train your\nmodels. It supports different ML algorithms and provides short-hand versions to\ntest multiple pre-treatment methods.</p>\n"}, {"fullname": "spectraxai.models.Model", "modulename": "spectraxai.models", "qualname": "Model", "type": "class", "doc": "<p>A class to describe commonly used ML models for spectral processing.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.models.Model.PLS", "modulename": "spectraxai.models", "qualname": "Model.PLS", "type": "variable", "doc": "<p></p>\n", "default_value": " = Partial Least Squares"}, {"fullname": "spectraxai.models.Model.SVR", "modulename": "spectraxai.models", "qualname": "Model.SVR", "type": "variable", "doc": "<p></p>\n", "default_value": " = Support Vector Regression"}, {"fullname": "spectraxai.models.Model.RF", "modulename": "spectraxai.models", "qualname": "Model.RF", "type": "variable", "doc": "<p></p>\n", "default_value": " = Random Forest"}, {"fullname": "spectraxai.models.Model.CUBIST", "modulename": "spectraxai.models", "qualname": "Model.CUBIST", "type": "variable", "doc": "<p></p>\n", "default_value": " = Cubist"}, {"fullname": "spectraxai.models.Model.XGBOOST", "modulename": "spectraxai.models", "qualname": "Model.XGBOOST", "type": "variable", "doc": "<p></p>\n", "default_value": " = XGBoost"}, {"fullname": "spectraxai.models.StandardModel", "modulename": "spectraxai.models", "qualname": "StandardModel", "type": "class", "doc": "<p>Class with standard models for ML to apply on spectral datasets.</p>\n"}, {"fullname": "spectraxai.models.StandardModel.__init__", "modulename": "spectraxai.models", "qualname": "StandardModel.__init__", "type": "function", "doc": "<p>Initialize StandardModel class for a <code>Model</code> and its hyperparameters.</p>\n\n<p>You need to pass either a set of hyperparameters for the model, or a range\nthereof in which to search for the optimal set.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (<code>Model</code>):\nSelect a model from <code>Model</code> class.</li>\n<li><strong>init_hyperparameters</strong> (<code>dict</code>, optional):\nA dictionary of pre-selected hyperparameters (e.g. a best model)</li>\n<li><strong>grid_search_hyperparameters</strong> (<code>dict</code>, optional):\nSpecify custom grid search range for the hyperparameters</li>\n</ul>\n", "signature": "(\n    self,\n    model: spectraxai.models.Model,\n    init_hyperparameters: Dict = {},\n    grid_search_hyperparameters: Dict = {}\n)", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.model", "modulename": "spectraxai.models", "qualname": "StandardModel.model", "type": "variable", "doc": "<p>The type of <code>Model</code> used</p>\n", "annotation": ": spectraxai.models.Model"}, {"fullname": "spectraxai.models.StandardModel.init_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.init_hyperparameters", "type": "variable", "doc": "<p>A dictionary of the hyperparameters of the models identified by an expert,\nto override a grid search</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.grid_search_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.grid_search_hyperparameters", "type": "variable", "doc": "<p>A dictionary containing as keys the hyperparameters of the model and as values\na list of the potential candidate values</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.best_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.best_hyperparameters", "type": "variable", "doc": "<p>A dictionary of the best hyperparameters, either set externally or as identified\nafter calling the train function</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.training_time", "modulename": "spectraxai.models", "qualname": "StandardModel.training_time", "type": "variable", "doc": "<p>Training time in seconds</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.testing_time", "modulename": "spectraxai.models", "qualname": "StandardModel.testing_time", "type": "variable", "doc": "<p>Time for the prediction in seconds</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.best_model", "modulename": "spectraxai.models", "qualname": "StandardModel.best_model", "type": "variable", "doc": "<p>The best optimized model after tuning the hyperparameters</p>\n", "annotation": ": sklearn.base.BaseEstimator"}, {"fullname": "spectraxai.models.StandardModel.best_score", "modulename": "spectraxai.models", "qualname": "StandardModel.best_score", "type": "variable", "doc": "<p>The best score (R2 for regression and accuracy for classification) in the\ninternal validation set corresponding to the best model</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.fit", "modulename": "spectraxai.models", "qualname": "StandardModel.fit", "type": "function", "doc": "<p>Trains the model on a given dataset.</p>\n\n<p>If you didn't supply the <code>init_hyperparameters</code> option to the constructor, then\na grid search optimization process takes place as follows:\nUsing the sklearn.model_selection.GridSearchCV approach, a grid search using a\ncross-validation splitting strategy specified by cv is performed. After the\noptimal hyperparameters are defined, the model is then retrained on the whole\ndataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>cv</strong> (int, or an iterable, default=5):\nDetermines the cross-validation splitting strategy.\nPossible inputs for cv are:\n<ul>\n<li>integer, to specify the number of folds</li>\n<li>An iterable yielding (train, test) splits as arrays of indices</li>\n</ul></li>\n</ul>\n", "signature": "(self, dataset: spectraxai.dataset.Dataset, cv: Union[int, List] = 5)", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.predict", "modulename": "spectraxai.models", "qualname": "StandardModel.predict", "type": "function", "doc": "<p>Predict using the best_model from a new unknown input.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X_test</strong> (<code>np.ndarray</code>):\nThe new input data to predict their output</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: A np.ndarray of size (n_test_samples, n_outputs) with the predictions</li>\n</ul>\n", "signature": "(self, X_test: numpy.ndarray) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.fit_and_predict", "modulename": "spectraxai.models", "qualname": "StandardModel.fit_and_predict", "type": "function", "doc": "<p>Train and test a model in given dataset and spectral pre-processing sequence.</p>\n\n<p>Pass here the whole dataset of (X, Y) and either specify\nidx_trn (training indices) or idx_tst (testing indices).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>preprocess</strong> (<code>spectraxai.spectra.SpectralPreprocessingSequence</code>):\nOptional pre-processing sequence. Defaults to SpectralPreprocessing.NONE.</li>\n<li><strong>idx_trn</strong> (<code>np.ndarray</code>):\nThe indices of the trn samples. Defaults to np.array([]).\nThis can either be a one dimensional array (for a single split), or\ntwo-dimensional to indicate a cross-validation split.</li>\n<li><strong>idx_tst</strong> (<code>np.ndarray</code>):\nThe indices of the tst samples. Defaults to np.array([]).\nThis can either be a one dimensional array (for a single split), or\ntwo-dimensional to indicate a cross-validation split.</li>\n<li><strong>get_model</strong> (<code>bool</code>):\nIf true, also return the generated model. Defaults to False.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>pandas.DataFrame</code></strong>: The accuracy results and assorted metadata for each output property</li>\n</ul>\n", "signature": "(\n    self,\n    dataset: spectraxai.dataset.Dataset,\n    preprocess: Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]] = no,\n    idx_trn: numpy.ndarray = array([], dtype=float64),\n    idx_tst: numpy.ndarray = array([], dtype=float64),\n    get_model: bool = False\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.fit_and_predict_multiple", "modulename": "spectraxai.models", "qualname": "StandardModel.fit_and_predict_multiple", "type": "function", "doc": "<p>Train a model using different pre-treatments and predict on the test set.</p>\n\n<p>A short-hand version to quickly test different pre-treatments methods,\ncalling the <code>fit_and_predict</code> function.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>preprocesses</strong> (<code>spectraxai.spectra.List[SpectralPreprocessingSequence]</code>):\nList of different pre-processing sequences to test. Defaults to [].</li>\n<li><strong>idx_trn</strong> (<code>np.ndarray</code>):\nThe indices of the trn samples. Defaults to np.array([]).</li>\n<li><strong>idx_tst</strong> (<code>np.ndarray</code>):\nThe indices of the tst samples. Defaults to np.array([]).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>pandas.DataFrame</code></strong>: Returns a dataframe with the results of the trained models.\nBy default, no model is returned to keep a low memory footprint.</li>\n</ul>\n", "signature": "(\n    self,\n    dataset: spectraxai.dataset.Dataset,\n    preprocesses: List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]] = [],\n    idx_trn: numpy.ndarray = array([], dtype=float64),\n    idx_tst: numpy.ndarray = array([], dtype=float64)\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "spectraxai.spectra", "modulename": "spectraxai.spectra", "type": "module", "doc": "<p>The module <code>spectraxai.spectra</code> supports operations on spectra.</p>\n\n<p>This module defines the class <code>Spectra</code> which can be used to hold spectral\ndatasets (only the features, e.g. reflectance values) and perform common\noperations on them like pre-processing.</p>\n"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing", "type": "class", "doc": "<p>Spectral Preprocessing enum.</p>\n\n<p>A collection of different spectral pre-processing (or pre- treatments) that\nmay be applied to a spectral matrix.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.NONE", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.NONE", "type": "variable", "doc": "<p></p>\n", "default_value": " = no"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.REF", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.REF", "type": "variable", "doc": "<p></p>\n", "default_value": " = reflectance"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.ABS", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.ABS", "type": "variable", "doc": "<p></p>\n", "default_value": " = absorbance"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SNV", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SNV", "type": "variable", "doc": "<p></p>\n", "default_value": " = SNV"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG0", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG0", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG0"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG1", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG1", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG1"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG2", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG2", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG2"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.CR", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.CR", "type": "variable", "doc": "<p></p>\n", "default_value": " = continuum-removal"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.init_class", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.init_class", "type": "function", "doc": "<p>Initialize from its string representation.</p>\n", "signature": "(string: str)", "funcdef": "def"}, {"fullname": "spectraxai.spectra.SpectralPreprocessingOptions", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessingOptions", "type": "variable", "doc": "<p>Either a single SpectralPreprocessing or a tuple specifying a\nSpectralPreprocessing and its assorted options (e.g. window_length for SG).</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>SpectralPreprocessing.CR =&gt; continuum-removal</li>\n<li>(SpectralPreprocessing.SG2, {\"window_length\": 7, \"polyorder\": 3}) =&gt;\nSG2 with window_length of 7 and polyorder of 3</li>\n</ul>\n", "default_value": " = typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]]]"}, {"fullname": "spectraxai.spectra.SpectralPreprocessingSequence", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessingSequence", "type": "variable", "doc": "<p>A sequence of one or more spectral pre-treatments applied together (e.g. SG1 + SNV)</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>SpectralPreprocessing.NONE =&gt; no pre-treatment</li>\n<li>[SpectralPreprocessing.ABS, SpectralPreprocessing.CR] =&gt; ABS + CR</li>\n<li>(SpectralPreprocessing.SG1, {\"window_length\": 7, \"polyorder\": 3}) =&gt;\nSG1 with window_length of 7 and polyorder of 3</li>\n<li>[(SpectralPreprocessing.SG1, {\"window_length\": 7}), SpectralPreprocessing.SNV] =&gt;\nSG1 + SNV</li>\n</ul>\n", "default_value": " = typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]], typing.List[typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]]]]]"}, {"fullname": "spectraxai.spectra.Spectra", "modulename": "spectraxai.spectra", "qualname": "Spectra", "type": "class", "doc": "<p>Spectra class to hold a 2-D spectral matrix of shape (samples, wavelengths).</p>\n\n<p>Can accept a 1-D vector as input but always returns a 2-D matrix.</p>\n"}, {"fullname": "spectraxai.spectra.Spectra.__init__", "modulename": "spectraxai.spectra", "qualname": "Spectra.__init__", "type": "function", "doc": "<p>X is a np 2D array containing the (samples, wavelengths) matrix.</p>\n", "signature": "(self, X: numpy.ndarray)", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.X", "modulename": "spectraxai.spectra", "qualname": "Spectra.X", "type": "variable", "doc": "<p>A 2-D matrix representing the spectra</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.spectra.Spectra.reflectance", "modulename": "spectraxai.spectra", "qualname": "Spectra.reflectance", "type": "function", "doc": "<p>Transform absorbance to reflectance.</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.absorbance", "modulename": "spectraxai.spectra", "qualname": "Spectra.absorbance", "type": "function", "doc": "<p>Transform reflectance to absorbance.</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.snv", "modulename": "spectraxai.spectra", "qualname": "Spectra.snv", "type": "function", "doc": "<p>Apply the standard normal variate transform.</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.sg", "modulename": "spectraxai.spectra", "qualname": "Spectra.sg", "type": "function", "doc": "<p>Apply a general Savitzky\u2013Golay transform.</p>\n\n<p>You need to pass as kwargs the parameters of\n<code>scipy.signal.savgol_filter</code></p>\n", "signature": "(self, **kwargs) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.cr", "modulename": "spectraxai.spectra", "qualname": "Spectra.cr", "type": "function", "doc": "<p>Transform absorbance spectra using the Continuum Removal.</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.preprocess", "modulename": "spectraxai.spectra", "qualname": "Spectra.preprocess", "type": "function", "doc": "<p>Apply a pre-processing sequence (i.e., one or more) specified by method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>spectraxai.spectra.SpectralPreprocessingSequence</code>):\nThe method for the preprocess.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Spectra</code></strong>: A new Spectra object, where X contains the preprocessed spectra.</li>\n</ul>\n", "signature": "(\n    self,\n    method: Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]\n) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.utils", "modulename": "spectraxai.utils", "type": "module", "doc": "<p>The module <code>spectraxai.utils</code> defines some utility functions.</p>\n\n<p>In general they are small functions to be used by the other modules.</p>\n"}, {"fullname": "spectraxai.utils.continuum_removal", "modulename": "spectraxai.utils", "qualname": "continuum_removal", "type": "function", "doc": "<p>Calculate the continuum removal pre-treatment.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>spectrum</strong> (<code>np.ndarray</code>):\nEither a vector or a matrix of the spectra signatures.</li>\n<li><strong>wvs</strong> (<code>list</code>, optional):\nAn optional list of the wavelengths</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: Either a vector or a matrix of the pre-processed spectra</li>\n</ul>\n", "signature": "(spectrum: numpy.ndarray, wvs: list = [])", "funcdef": "def"}, {"fullname": "spectraxai.utils.sigest", "modulename": "spectraxai.utils", "qualname": "sigest", "type": "function", "doc": "<p>Estimate SVM/SVR $\\gamma$ based on 0.1 - 0.9 quantile of $||x-x'||^2$.</p>\n\n<p>Based on sigest function of kernlab. More details may be found here:</p>\n\n<ul>\n<li>https://www.rdocumentation.org/packages/kernlab/</li>\n<li>https://rdrr.io/cran/kernlab/src/R/sigest.R</li>\n</ul>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (<code>np.ndarray</code>):\nA 2D numpy array containing the input features</li>\n<li><strong>frac</strong> (<code>float</code>):\nThe fraction of the data used to estimate the value</li>\n<li><strong>scale</strong> (<code>bool</code>):\nWhether to scale the input array or not. Defaults to True.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: A 1D numpy array of exactly 3 suggested sorted values.</li>\n</ul>\n", "signature": "(x, frac=0.5, scale=True)", "funcdef": "def"}, {"fullname": "spectraxai.utils.estimate_C", "modulename": "spectraxai.utils", "qualname": "estimate_C", "type": "function", "doc": "<p>Estimate SVR C from $\\max{(|\\overline{y}-3\\sigma_y|,|\\overline{y}+3\\sigma_y|)}$.</p>\n\n<p>Rule-of-thumb from dx.doi.org/10.1016/S0893-6080(03)00169-2, Eq. 13.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y</strong> (<code>np.ndarray</code>):\nA 1-D np array containing the output values</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>float</code></strong>: A float value with a suggestion for C</li>\n</ul>\n", "signature": "(y)", "funcdef": "def"}, {"fullname": "spectraxai.utils.estimate_epsilon", "modulename": "spectraxai.utils", "qualname": "estimate_epsilon", "type": "function", "doc": "<p>Estimate SVR $\\epsilon$ based on the noise variance.</p>\n\n<p>See Equations 17 and 22 of https://dx.doi.org/10.1016/S0893-6080(03)00169-2.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>np.ndarray</code>):\nThe input features in 2-D format</li>\n<li><strong>Y</strong> (<code>np.ndarray</code>):\nThe output vector in 1-D format</li>\n<li><strong>ndegree</strong> (<code>int</code>):\nThe degree of the polynomial fit. Defaults to 5.</li>\n<li><strong>half_features</strong> (<code>bool</code>):\nWhether to use half of the features for faster estimations. Defaults to False.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>float</code></strong>: An estimated optimal value for $\\epsilon$</li>\n</ul>\n", "signature": "(X, Y, ndegree=5, half_features=False)", "funcdef": "def"}, {"fullname": "spectraxai.utils.metrics", "modulename": "spectraxai.utils", "qualname": "metrics", "type": "function", "doc": "<p>Calculate accuracy metrics for regression.</p>\n\n<p>Returns a dictionary containing RMSE (Root Mean Squared Error), $R^2$ (coefficient\nof determination) and RPIQ (Ratio of Performance to InterQuartile distance).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_true</strong> (<code>np.ndarray</code>):\nA 1D vector of the true output (also known as observed)</li>\n<li><strong>y_pred</strong> (<code>np.ndarray</code>):\nA 1D vector of the predicted output (e.g., by a model)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>dict</code> [<code>str</code>, <code>float</code>]</strong>: A dictionary containing the name of the accuracy metric and its value.\nReturns RMSE, R2 and RPIQ.</li>\n</ul>\n", "signature": "(y_true: numpy.ndarray, y_pred: numpy.ndarray)", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();