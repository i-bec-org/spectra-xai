window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "spectraxai", "modulename": "spectraxai", "type": "module", "doc": "<h1 id=\"spectraxai\">SpectraXAI</h1>\n\n<p>A library to easily develop XAI models for spectral datasets.</p>\n\n<h2 id=\"features\">Features</h2>\n\n<ul>\n<li>Easy setup with pip</li>\n<li>Documented using pdoc following the numpydoc style </li>\n</ul>\n\n<h1 id=\"quickstart\">Quickstart</h1>\n\n<p>As an example, we quickly develop a PLS model for a dataset and quickly plot the feature importance.</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"sd\">&quot;&quot;&quot;</span>\n<span class=\"sd\">A small `spectraxai` example.</span>\n<span class=\"sd\">&quot;&quot;&quot;</span>\n\n<span class=\"c1\"># Load the dataset</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.utils.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_GR_SSL</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">load_GR_SSL</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Apply SG1 on the spectra and train &amp; test a PLS model</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.models</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span><span class=\"p\">,</span> <span class=\"n\">StandardModel</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.spectra</span> <span class=\"kn\">import</span> <span class=\"n\">SpectralPreprocessing</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.dataset</span> <span class=\"kn\">import</span> <span class=\"n\">DatasetSplit</span>\n\n<span class=\"n\">idx_trn</span><span class=\"p\">,</span> <span class=\"n\">idx_tst</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">DatasetSplit</span><span class=\"o\">.</span><span class=\"n\">KENNARD_STONE</span><span class=\"p\">,</span> <span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">pls</span> <span class=\"o\">=</span> <span class=\"n\">StandardModel</span><span class=\"p\">(</span><span class=\"n\">Model</span><span class=\"o\">.</span><span class=\"n\">PLS</span><span class=\"p\">)</span>\n\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">pls</span><span class=\"o\">.</span><span class=\"n\">train_and_test</span><span class=\"p\">(</span>\n    <span class=\"n\">dataset</span><span class=\"p\">,</span> \n    <span class=\"n\">preprocess</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">SpectralPreprocessing</span><span class=\"o\">.</span><span class=\"n\">SG1</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">&quot;window_length&quot;</span><span class=\"p\">:</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"s2\">&quot;polyorder&quot;</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">}),</span> \n    <span class=\"n\">idx_trn</span><span class=\"o\">=</span><span class=\"n\">idx_trn</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Plot the feature importance</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spectraxai.explain</span> <span class=\"kn\">import</span> <span class=\"n\">PostHocAnalysis</span>\n\n<span class=\"n\">xai</span> <span class=\"o\">=</span> <span class=\"n\">PostHocAnalysis</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">xai</span><span class=\"o\">.</span><span class=\"n\">bar_plot_importance</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"s2\">&quot;feature_importance&quot;</span><span class=\"p\">])</span>\n</code></pre></div>\n"}, {"fullname": "spectraxai.dataset", "modulename": "spectraxai.dataset", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.dataset.Scale", "modulename": "spectraxai.dataset", "qualname": "Scale", "type": "class", "doc": "<p>Scaling of an input feature (or of the output) supported by the <code>Dataset</code> class</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.dataset.Scale.STANDARD", "modulename": "spectraxai.dataset", "qualname": "Scale.STANDARD", "type": "variable", "doc": "<p>Standard scaling, i.e. removing the mean and scaling to unit variance</p>\n", "default_value": " = standard"}, {"fullname": "spectraxai.dataset.Scale.MINMAX", "modulename": "spectraxai.dataset", "qualname": "Scale.MINMAX", "type": "variable", "doc": "<p>Scale and translate so that the range is between zero and one</p>\n", "default_value": " = min-max"}, {"fullname": "spectraxai.dataset.DatasetSplit", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit", "type": "class", "doc": "<p>Types of dataset split supported by the <code>Dataset</code> class</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.dataset.DatasetSplit.RANDOM", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.RANDOM", "type": "variable", "doc": "<p></p>\n", "default_value": " = random"}, {"fullname": "spectraxai.dataset.DatasetSplit.KENNARD_STONE", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.KENNARD_STONE", "type": "variable", "doc": "<p></p>\n", "default_value": " = Kennard-Stone"}, {"fullname": "spectraxai.dataset.DatasetSplit.CLHS", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.CLHS", "type": "variable", "doc": "<p></p>\n", "default_value": " = clhs"}, {"fullname": "spectraxai.dataset.DatasetSplit.CROSS_VALIDATION", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.CROSS_VALIDATION", "type": "variable", "doc": "<p></p>\n", "default_value": " = cross-validation"}, {"fullname": "spectraxai.dataset.DatasetSplit.STRATIFIED", "modulename": "spectraxai.dataset", "qualname": "DatasetSplit.STRATIFIED", "type": "variable", "doc": "<p></p>\n", "default_value": " = stratified"}, {"fullname": "spectraxai.dataset.DataSplit", "modulename": "spectraxai.dataset", "qualname": "DataSplit", "type": "variable", "doc": "<p>A tuple representing a split for the <code>Dataset</code> into training and testing indices</p>\n", "default_value": " = typing.Tuple[numpy.ndarray, numpy.ndarray]"}, {"fullname": "spectraxai.dataset.Dataset", "modulename": "spectraxai.dataset", "qualname": "Dataset", "type": "class", "doc": "<p>A general class to manage the dataset (i.e. input X and output Y).</p>\n\n<p>Use this class to pass your 2D spectral matrix and 1D or 2D output properties.\nSupports methods for pre-processing X, scaling X and Y, splitting the dataset, and more.</p>\n"}, {"fullname": "spectraxai.dataset.Dataset.__init__", "modulename": "spectraxai.dataset", "qualname": "Dataset.__init__", "type": "function", "doc": "<p>Create a new Dataset from input and output arrays</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D matrix of the spectra of size (<code>n_samples</code>, <code>n_features</code>)</li>\n<li><strong>Y</strong> (<code>numpy.ndarray</code>):\nA 1D vector (<code>n_samples</code>,) or 2D matrix (<code>n_samples</code>, <code>n_outputs</code>) of the output property(ies).\nIf 1D it will be implicitly converted to 2D.</li>\n<li><strong>X_names</strong> (<code>list[str]</code>, optional):\nA list of length n_features containing the names of the input features.\nIf missing, these will be autogenerated as X1, X2, etc.</li>\n<li><strong>Y_names</strong> (<code>list[str]</code>, optional):\nA list of length n_outputs containing the names of the output properties.\nWhen using a single output property pass a list of size 1.\nIf missing, these will be autogenerated as Y1, Y2, etc.</li>\n</ul>\n", "signature": "(\n    self,\n    X: numpy.ndarray,\n    Y: numpy.ndarray,\n    X_names: List[str] = [],\n    Y_names: List[str] = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.n_samples", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_samples", "type": "variable", "doc": "<p>Number of samples in the dataset</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.n_features", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_features", "type": "variable", "doc": "<p>Number of features in the dataset's input</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.n_outputs", "modulename": "spectraxai.dataset", "qualname": "Dataset.n_outputs", "type": "variable", "doc": "<p>Number of outputs in the dataset's output</p>\n", "annotation": ": int"}, {"fullname": "spectraxai.dataset.Dataset.X", "modulename": "spectraxai.dataset", "qualname": "Dataset.X", "type": "variable", "doc": "<p>The spectral data of size (<code>n_samples</code>, <code>n_features</code>)</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.dataset.Dataset.Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.Y", "type": "variable", "doc": "<p>The output properties of size (<code>n_samples</code>, <code>n_outputs</code>)</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.dataset.Dataset.X_names", "modulename": "spectraxai.dataset", "qualname": "Dataset.X_names", "type": "variable", "doc": "<p>The names of the input features of size (<code>n_features</code>)</p>\n", "annotation": ": List[str]"}, {"fullname": "spectraxai.dataset.Dataset.Y_names", "modulename": "spectraxai.dataset", "qualname": "Dataset.Y_names", "type": "variable", "doc": "<p>The names of the output properties of size (<code>n_outputs</code>)</p>\n", "annotation": ": List[str]"}, {"fullname": "spectraxai.dataset.Dataset.train_test_split", "modulename": "spectraxai.dataset", "qualname": "Dataset.train_test_split", "type": "function", "doc": "<p>Splits dataset with passed split method to train and test.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>split</strong> (<code>DatasetSplit</code>):\nThe method used to split the dataset</li>\n<li><strong>opt</strong> (<code>Number</code>):\nA float number (between 0 and 1) indicating the percentage of the training dataset for Random and Kennard\u2013Stone split.\nA natural number for Cross Validation and Stratified split.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>DataSplit</code></strong>: The idx_trn, idx_tst tuple. Use e.g. X[idx_trn], Y[idx_trn] to get the training dataset.</li>\n</ul>\n", "signature": "(\n    self,\n    split: spectraxai.dataset.DatasetSplit,\n    opt: numbers.Number\n) -> Tuple[numpy.ndarray, numpy.ndarray]", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.subset", "modulename": "spectraxai.dataset", "qualname": "Dataset.subset", "type": "function", "doc": "<p>Subset the dataset using passed indices</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>idx</strong> (np.ndarray):\nThe indices to subset by</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A new subsetted Dataset</li>\n</ul>\n", "signature": "(self, idx: numpy.ndarray) -> spectraxai.dataset.Dataset", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.train_test_split_explicit", "modulename": "spectraxai.dataset", "qualname": "Dataset.train_test_split_explicit", "type": "function", "doc": "<p>Splits dataset to train and test from pre-selected by the user trn or tst indices.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>trn</strong> (np.ndarray, optional):\nContains the indices of the training samples</li>\n<li><strong>tst</strong> (np.ndarray, optional):\nContains the indices of the testing samples</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>DataSplit</code></strong>: The idx_trn, idx_tst tuple</li>\n</ul>\n", "signature": "(\n    self,\n    trn: <built-in function array> = array([], dtype=float64),\n    tst: <built-in function array> = array([], dtype=float64)\n) -> Tuple[numpy.ndarray, numpy.ndarray]", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.preprocess", "modulename": "spectraxai.dataset", "qualname": "Dataset.preprocess", "type": "function", "doc": "<p>Preprocess dataset by method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>spectraxai.spectra.SpectralPreprocessingSequence</code>):\nThe method for the preprocess.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A new Dataset object.</li>\n</ul>\n", "signature": "(\n    self,\n    method: List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]]\n) -> spectraxai.dataset.Dataset", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.preprocess_3D", "modulename": "spectraxai.dataset", "qualname": "Dataset.preprocess_3D", "type": "function", "doc": "<p>Preprocess spectra into a new 3D matrix by methods in a list structure.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>methods</strong> (<code>List[SpectralPreprocessingSequence]</code>):\nThe methods for the preprocess.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>numpy.ndarray</code></strong>: A 3D matrix of size (<code>n_samples</code>, <code>n_features</code>, n_preprocesses)</li>\n</ul>\n", "signature": "(\n    self,\n    methods: List[List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]]]\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.apply_unscale_X", "modulename": "spectraxai.dataset", "qualname": "Dataset.apply_unscale_X", "type": "function", "doc": "<p>Unscale X matrix of the spectra with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale X</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D or 3D matrix of the spectra for scaled X hat</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>numpy.ndarray</code></strong>: The original X matrix of the spectra. If X, set_params and set_attributes have been given for parameters.</li>\n<li><strong>or</strong></li>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = [],\n    X: numpy.ndarray = array([], dtype=float64)\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.unscale_X", "modulename": "spectraxai.dataset", "qualname": "Dataset.unscale_X", "type": "function", "doc": "<p>Static unscale for X matrix of the spectra with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D or 3D scaled matrix of the spectra.</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale X</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>numpy.ndarray</code></strong>: The original X matrix of the spectra.</li>\n</ul>\n", "signature": "(\n    X: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.apply_scale_X", "modulename": "spectraxai.dataset", "qualname": "Dataset.apply_scale_X", "type": "function", "doc": "<p>Scale X matrix of the spectra with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method used is to scale 2D or 3D X matrix of the spectra.</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.scale_X", "modulename": "spectraxai.dataset", "qualname": "Dataset.scale_X", "type": "function", "doc": "<p>Static scale method of X matrix of the spectra with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (<code>numpy.ndarray</code>):\nA 2D or 3D matrix of the spectra.</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale X</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    X: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.apply_unscale_Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.apply_unscale_Y", "type": "function", "doc": "<p>Unscale a 1D vector or 2D matrix of the output property(ies) with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale Y</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n<li><strong>Y</strong> (<code>numpy.ndarray</code>):\nA 1D vector or 2D matrix of the output property(ies).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>numpy.ndarray</code></strong>: The original 1D or 2D matrix Y. If Y, set_params and set_attributes have been given for parameters.</li>\n<li><strong>or</strong></li>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = [],\n    Y: numpy.ndarray = array([], dtype=float64)\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.unscale_Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.unscale_Y", "type": "function", "doc": "<p>Static unscale method for a 1D vector or 2D matrix of the output property(ies) with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>Y</strong> (<code>numpy.ndarray</code>):\nA scaled 1D vector or 2D matrix of the output property(ies)</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale Y</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>numpy.ndarray</code></strong>: The original 1D or 2D matrix Y</li>\n</ul>\n", "signature": "(\n    Y: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.apply_scale_Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.apply_scale_Y", "type": "function", "doc": "<p>Scale a 1D vector or 2D matrix of the output property(ies) with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale Y</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.dataset.Dataset.scale_Y", "modulename": "spectraxai.dataset", "qualname": "Dataset.scale_Y", "type": "function", "doc": "<p>Static scale method for a 1D vector or 2D matrix of the output property(ies) with Scale method.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>Y</strong> (<code>numpy.ndarray</code>):\nA scaled 1D vector or 2D matrix of the output property(ies).</li>\n<li><strong>method</strong> (<code>Scale</code>):\nThe method is used to scale Y</li>\n<li><strong>set_params</strong> (<code>List</code>):\nA list of dicts with the parameters of each Scale method.</li>\n<li><strong>set_attributes</strong> (<code>List</code>):\nA list of dicts with the attributes of each Scale method.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>Dataset</code></strong>: A Dataset object.</li>\n</ul>\n", "signature": "(\n    Y: numpy.ndarray,\n    method: spectraxai.dataset.Scale,\n    set_params: List = [],\n    set_attributes: List = []\n)", "funcdef": "def"}, {"fullname": "spectraxai.explain", "modulename": "spectraxai.explain", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.explain.FeatureRanking", "modulename": "spectraxai.explain", "qualname": "FeatureRanking", "type": "class", "doc": "<p>Types of methods for calculating feature ranking</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.explain.FeatureRanking.CORR", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.CORR", "type": "variable", "doc": "<p></p>\n", "default_value": " = Pearson's correlation"}, {"fullname": "spectraxai.explain.FeatureRanking.MI", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.MI", "type": "variable", "doc": "<p></p>\n", "default_value": " = Mutual information"}, {"fullname": "spectraxai.explain.FeatureRanking.F_STATISTIC", "modulename": "spectraxai.explain", "qualname": "FeatureRanking.F_STATISTIC", "type": "variable", "doc": "<p></p>\n", "default_value": " = F-statistic"}, {"fullname": "spectraxai.explain.PreHocAnalysis", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis", "type": "class", "doc": "<p>A class to provide methods for providing pre-hoc explainability analysis.</p>\n", "bases": "_Explain"}, {"fullname": "spectraxai.explain.PreHocAnalysis.feature_importance", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.feature_importance", "type": "function", "doc": "<p>Calculate the feature importance between the input features and the output(s).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>FeatureRanking</code>):\nThe method to calculate the feature importance.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: The feature importance according to the selected method, which is a 2-D np.array\ncontaining the ranking for each output property of size\n(<code>spectraxai.dataset.Dataset.n_outputs</code>, <code>spectraxai.dataset.Dataset.n_features</code>)</li>\n</ul>\n", "signature": "(self, method: spectraxai.explain.FeatureRanking) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.correlogram", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.correlogram", "type": "function", "doc": "<p>Plot a correlogram between the most important input features and the output(s).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>top</strong> (<code>int</code>, optional):\nThe number of most important features to consider. Defaults to 5.</li>\n<li><strong>method</strong> (<code>FeatureRanking</code>, optional):\nThe method to calculate the feature importance. Defaults to FeatureRanking.CORR.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    top: int = 5,\n    method: spectraxai.explain.FeatureRanking = Pearson's correlation\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.bar_plot_importance", "type": "function", "doc": "<p>Plot a bar plot depicting the feature ranking between the input features and the output(s).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>method</strong> (<code>FeatureRanking</code>, optional):\nThe method to calculate the feature importance. Defaults to FeatureRanking.CORR.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    method: spectraxai.explain.FeatureRanking = Pearson's correlation\n)", "funcdef": "def"}, {"fullname": "spectraxai.explain.PreHocAnalysis.mean_spectrum_by_range", "modulename": "spectraxai.explain", "qualname": "PreHocAnalysis.mean_spectrum_by_range", "type": "function", "doc": "<p>Creates a plot of the mean spectrum (across all samples) for each output range.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_ranges</strong> (List[np.array]):\nA list of length <code>spectraxai.dataset.n_outputs</code> containing the ranges to calculate the mean spectrum wrapped in an np.array.\nFor example np.array([0, 1, 5]) means calculate the means from outputs 0 to 1 and 1 to 5.</li>\n<li><strong>preprocesses</strong> (<code>List[spectraxai.spectra.SpectralPreprocessing]</code>, optional):\nAn optional list of preprocessing techniques to plot simultaneously on the same figure.\nIf omitted, it will only plot the spectra of the passed dataset.</li>\n<li><strong>ylims</strong> (List[List], optional):\nAn optional list of the ylim to use on each of the supplied preprocesses.\nIf preprocesses was omitted this can be a list of length 1 to act on the dataset's spectra.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    y_ranges: List,\n    preprocesses: List[spectraxai.spectra.SpectralPreprocessing] = [],\n    ylims: List = []\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis", "type": "class", "doc": "<p>A class to provide methods for providing post-hoc explainability analysis.</p>\n", "bases": "_Explain"}, {"fullname": "spectraxai.explain.PostHocAnalysis.bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.bar_plot_importance", "type": "function", "doc": "<p>Plots a bar plot of the feature importance</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>importance</strong> (<code>np.ndarray</code>):\nA numpy array of shape (<code>spectraxai.dataset.Dataset.n_features</code>,1)\ncontaining the importance of each feature</li>\n<li><strong>ax</strong> (<code>plt.Axes</code>, optional):\nAn optional matplotlib axes to plot into. Defaults to None,\nin which case a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    importance: numpy.ndarray,\n    ax: matplotlib.axes._axes.Axes = None\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.circular_bar_plot_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.circular_bar_plot_importance", "type": "function", "doc": "<p>Plots a circular (spiral) bar plot of the feature importance</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>importance</strong> (<code>np.ndarray</code>):\nA numpy array of shape (<code>spectraxai.dataset.Dataset.n_features</code>,1)\ncontaining the importance of each feature</li>\n<li><strong>ax</strong> (`plt.Axes):\nAn optional matplotlib axes to plot into. Defaults to None,\nin which case a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    importance: numpy.ndarray,\n    ax: matplotlib.axes._axes.Axes = None,\n    top: int = None\n) -> matplotlib.axes._axes.Axes", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.bar_plot_permutation_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.bar_plot_permutation_importance", "type": "function", "doc": "<p>Create a bar plot using ermutation feature importance</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (object):\nThe estimator that has already been fitted</li>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>, optional):\nAn optional dataset to calculate the scoring, which can be a hold-out set\ndifferent from the training data used to train the estimator. If this is\nnot supplied, <code>dataset</code> will be used instead.</li>\n<li><strong>ax</strong> (<code>plt.Axes</code>, optional):\nAn optional matplotlib axes to plot into. Defaults to None, in which\ncase a new figure is created.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>plt.Axes</code></strong>: The matplotlib axes with the plot</li>\n</ul>\n", "signature": "(\n    self,\n    model,\n    dataset: spectraxai.dataset.Dataset = None,\n    ax: <function axes at 0x7f5afbd3b250> = None\n)", "funcdef": "def"}, {"fullname": "spectraxai.explain.PostHocAnalysis.sage_importance", "modulename": "spectraxai.explain", "qualname": "PostHocAnalysis.sage_importance", "type": "function", "doc": "<p></p>\n", "signature": "(self, model)", "funcdef": "def"}, {"fullname": "spectraxai.models", "modulename": "spectraxai.models", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.models.Model", "modulename": "spectraxai.models", "qualname": "Model", "type": "class", "doc": "<p>A model class to describe commonly used ML models for spectral processing</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.models.Model.PLS", "modulename": "spectraxai.models", "qualname": "Model.PLS", "type": "variable", "doc": "<p></p>\n", "default_value": " = Partial Least Squares"}, {"fullname": "spectraxai.models.Model.SVR", "modulename": "spectraxai.models", "qualname": "Model.SVR", "type": "variable", "doc": "<p></p>\n", "default_value": " = Support Vector Regression"}, {"fullname": "spectraxai.models.Model.RF", "modulename": "spectraxai.models", "qualname": "Model.RF", "type": "variable", "doc": "<p></p>\n", "default_value": " = Random Forest"}, {"fullname": "spectraxai.models.Model.CUBIST", "modulename": "spectraxai.models", "qualname": "Model.CUBIST", "type": "variable", "doc": "<p></p>\n", "default_value": " = Cubist"}, {"fullname": "spectraxai.models.StandardModel", "modulename": "spectraxai.models", "qualname": "StandardModel", "type": "class", "doc": "<p>Class with standard models for machine learning that can be applied to spectral datasets</p>\n"}, {"fullname": "spectraxai.models.StandardModel.__init__", "modulename": "spectraxai.models", "qualname": "StandardModel.__init__", "type": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (<code>Model</code>):\nSelect a model from <code>Model</code> class.</li>\n<li><strong>init_hyperparameters</strong> (<code>dict</code>, optional):\nA dictionary of pre-selected hyperparameters (e.g. a best model)</li>\n<li><strong>grid_search_hyperparameters</strong> (<code>dict</code>, optional):\nSpecify custom grid search range for the hyperparameters</li>\n</ul>\n", "signature": "(\n    self,\n    model: spectraxai.models.Model,\n    init_hyperparameters: Dict = {},\n    grid_search_hyperparameters: Dict = {}\n)", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.model", "modulename": "spectraxai.models", "qualname": "StandardModel.model", "type": "variable", "doc": "<p>The type of <code>Model</code> used</p>\n", "annotation": ": spectraxai.models.Model"}, {"fullname": "spectraxai.models.StandardModel.init_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.init_hyperparameters", "type": "variable", "doc": "<p>A dictionary of the hyperparameters of the models identified by an expert, to override a grid search</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.grid_search_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.grid_search_hyperparameters", "type": "variable", "doc": "<p>A dictionary containing as keys the hyperparameters of the model and as values a list of the potential candidate values</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.best_hyperparameters", "modulename": "spectraxai.models", "qualname": "StandardModel.best_hyperparameters", "type": "variable", "doc": "<p>A dictionary of the best hyperparameters, either set externally or as identified after calling the train function</p>\n", "annotation": ": Dict"}, {"fullname": "spectraxai.models.StandardModel.training_time", "modulename": "spectraxai.models", "qualname": "StandardModel.training_time", "type": "variable", "doc": "<p>Training time in seconds</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.testing_time", "modulename": "spectraxai.models", "qualname": "StandardModel.testing_time", "type": "variable", "doc": "<p>Time for the prediction in seconds</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.best_model", "modulename": "spectraxai.models", "qualname": "StandardModel.best_model", "type": "variable", "doc": "<p>The best optimized model after tuning the hyperparameters</p>\n", "annotation": ": sklearn.base.BaseEstimator"}, {"fullname": "spectraxai.models.StandardModel.best_score", "modulename": "spectraxai.models", "qualname": "StandardModel.best_score", "type": "variable", "doc": "<p>The best score (R2 for regression and accuracy for classification) in the internal validation set corresponding to the best model</p>\n", "annotation": ": float"}, {"fullname": "spectraxai.models.StandardModel.train", "modulename": "spectraxai.models", "qualname": "StandardModel.train", "type": "function", "doc": "<p>Trains the model on a given dataset.</p>\n\n<p>If you didn't supply the <code>init_hyperparameters</code> option to the constructor, then\na grid search optimization process takes place as follows:\nUsing the sklearn.model_selection.GridSearchCV approach, a grid search using a\ncross-validation splitting strategy specified by cv is performed. After the optimal\nhyperparameters are defined, the model is then retrained on the whole dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>cv</strong> (int, or an iterable, default=5):\nDetermines the cross-validation splitting strategy.\nPossible inputs for cv are:\n<ul>\n<li>integer, to specify the number of folds</li>\n<li>An iterable yielding (train, test) splits as arrays of indices</li>\n</ul></li>\n</ul>\n", "signature": "(self, dataset: spectraxai.dataset.Dataset, cv: Union[int, List] = 5)", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.predict", "modulename": "spectraxai.models", "qualname": "StandardModel.predict", "type": "function", "doc": "<p>Predict using the best_model from a new unknown input</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X_test</strong> (<code>np.ndarray</code>):\nThe new input data to predict their output</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>np.ndarray</code></strong>: A np.ndarray of size (n_test_samples, n_outputs) with the predictions</li>\n</ul>\n", "signature": "(self, X_test: numpy.ndarray) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.train_and_test", "modulename": "spectraxai.models", "qualname": "StandardModel.train_and_test", "type": "function", "doc": "<p>Trains and tests a model given a dataset and a spectral pre-processing sequence.</p>\n\n<p>Pass here the whole dataset of (X, Y) and either specify idx_trn (training indices) or idx_tst (testing indices).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>preprocess</strong> (<code>spectraxai.spectra.SpectralPreprocessingSequence</code>):\nOptional pre-processing sequence. Defaults to SpectralPreprocessing.NONE.</li>\n<li><strong>idx_trn</strong> (<code>np.array</code>):\nThe indices of the trn samples. Defaults to np.array([]).</li>\n<li><strong>idx_tst</strong> (<code>np.array</code>):\nThe indices of the tst samples. Defaults to np.array([]).</li>\n<li><strong>get_model</strong> (<code>bool</code>):\nIf true, also return the generated model. Defaults to False.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>pandas.DataFrame</code></strong>: The accuracy results and assorted metadata for each output property</li>\n</ul>\n", "signature": "(\n    self,\n    dataset: spectraxai.dataset.Dataset,\n    preprocess: List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]] = no,\n    idx_trn: numpy.ndarray = array([], dtype=float64),\n    idx_tst: numpy.ndarray = array([], dtype=float64),\n    get_model: bool = False\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "spectraxai.models.StandardModel.train_and_test_multiple", "modulename": "spectraxai.models", "qualname": "StandardModel.train_and_test_multiple", "type": "function", "doc": "<p>Train a model using different SpectralPreprocessingSequences and predict on the test set</p>\n\n<p>A short-hand version to quickly test different pre-treatments, calling the train_and_test function</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (<code>spectraxai.dataset.Dataset</code>):\nthe Dataset to train the model</li>\n<li><strong>preprocesses</strong> (<code>spectraxai.spectra.List[SpectralPreprocessingSequence]</code>):\nList of different pre-processing sequences to test. Defaults to [].</li>\n<li><strong>idx_trn</strong> (<code>np.array</code>):\nThe indices of the trn samples. Defaults to np.array([]).</li>\n<li><strong>idx_tst</strong> (<code>np.array</code>):\nThe indices of the tst samples. Defaults to np.array([]).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong><code>pandas.DataFrame</code></strong>: Returns a dataframe with the results of the trained models.\nBy default, no model is returned to keep a low memory footprint.</li>\n</ul>\n", "signature": "(\n    self,\n    dataset: spectraxai.dataset.Dataset,\n    preprocesses: List[List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]], List[Union[spectraxai.spectra.SpectralPreprocessing, Tuple[spectraxai.spectra.SpectralPreprocessing, Dict[str, int]]]]]]] = [],\n    idx_trn: numpy.ndarray = array([], dtype=float64),\n    idx_tst: numpy.ndarray = array([], dtype=float64)\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "spectraxai.spectra", "modulename": "spectraxai.spectra", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing", "type": "class", "doc": "<p>Spectral Preprocessing enum</p>\n\n<p>A collection of different spectral pre-processing (or pre-treatments)\nthat may be applied to a spectral matrix.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.NONE", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.NONE", "type": "variable", "doc": "<p></p>\n", "default_value": " = no"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.REF", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.REF", "type": "variable", "doc": "<p></p>\n", "default_value": " = reflectance"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.ABS", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.ABS", "type": "variable", "doc": "<p></p>\n", "default_value": " = absorbance"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SNV", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SNV", "type": "variable", "doc": "<p></p>\n", "default_value": " = SNV"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG0", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG0", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG0"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG1", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG1", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG1"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.SG2", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.SG2", "type": "variable", "doc": "<p></p>\n", "default_value": " = SG2"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.CR", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.CR", "type": "variable", "doc": "<p></p>\n", "default_value": " = continuum-removal"}, {"fullname": "spectraxai.spectra.SpectralPreprocessing.init_class", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessing.init_class", "type": "function", "doc": "<p>Initialize a SpectralPreprocessing object from its string representation</p>\n", "signature": "(string: str)", "funcdef": "def"}, {"fullname": "spectraxai.spectra.SpectralPreprocessingOptions", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessingOptions", "type": "variable", "doc": "<p>Either a single SpectralPreprocessing or a tuple specifying a SpectralPreprocessing and its assorted options (e.g. window_length for SG).</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>SpectralPreprocessing.CR =&gt; continuum-removal</li>\n<li>(SpectralPreprocessing.SG2, {\"window_length\": 7, \"polyorder\": 3}) =&gt; SG2 with window_length of 7 and polyorder of 3</li>\n</ul>\n", "default_value": " = typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]]]"}, {"fullname": "spectraxai.spectra.SpectralPreprocessingSequence", "modulename": "spectraxai.spectra", "qualname": "SpectralPreprocessingSequence", "type": "variable", "doc": "<p>A sequence of one or more spectral pre-treatments (e.g. SG1 + SNV)</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>[SpectralPreprocessing.NONE] =&gt; no pre-treatment</li>\n<li>[SpectralPreprocessing.ABS, SpectralPreprocessing.CR] =&gt; ABS + CR</li>\n<li>[(SpectralPreprocessing.SG1, {\"window_length\": 7}), SpectralPreprocessing.SNV] =&gt; SG1 + SNV</li>\n</ul>\n", "default_value": " = typing.List[typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]], typing.List[typing.Union[spectraxai.spectra.SpectralPreprocessing, typing.Tuple[spectraxai.spectra.SpectralPreprocessing, typing.Dict[str, int]]]]]]"}, {"fullname": "spectraxai.spectra.Spectra", "modulename": "spectraxai.spectra", "qualname": "Spectra", "type": "class", "doc": "<p>Spectra class to hold a 2-D spectral matrix.</p>\n\n<p>Can accept a 1-D vector but always returns a 2-D matrix.</p>\n"}, {"fullname": "spectraxai.spectra.Spectra.__init__", "modulename": "spectraxai.spectra", "qualname": "Spectra.__init__", "type": "function", "doc": "<p>X is a np 2D array containing the (samples, wavelengths) matrix</p>\n", "signature": "(self, X: numpy.ndarray)", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.X", "modulename": "spectraxai.spectra", "qualname": "Spectra.X", "type": "variable", "doc": "<p>A 2-D matrix representing the spectra</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "spectraxai.spectra.Spectra.reflectance", "modulename": "spectraxai.spectra", "qualname": "Spectra.reflectance", "type": "function", "doc": "<p>Transform absorbance to reflectance</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.absorbance", "modulename": "spectraxai.spectra", "qualname": "Spectra.absorbance", "type": "function", "doc": "<p>Transform reflectance to absorbance</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.snv", "modulename": "spectraxai.spectra", "qualname": "Spectra.snv", "type": "function", "doc": "<p>Apply the standard normal variate transform</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.sg", "modulename": "spectraxai.spectra", "qualname": "Spectra.sg", "type": "function", "doc": "<p>Apply a general Savitzky\u2013Golay transform.</p>\n\n<p>You need to pass as kwargs the parameters of <code>scipy.signal.savgol_filter</code></p>\n", "signature": "(self, **kwargs) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.cr", "modulename": "spectraxai.spectra", "qualname": "Spectra.cr", "type": "function", "doc": "<p>Transform absorbance spectra using the Continuum Removal</p>\n", "signature": "(self) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.spectra.Spectra.apply", "modulename": "spectraxai.spectra", "qualname": "Spectra.apply", "type": "function", "doc": "<p>Apply the transform specified by method</p>\n", "signature": "(\n    self,\n    method: spectraxai.spectra.SpectralPreprocessing,\n    **kwargs\n) -> spectraxai.spectra.Spectra", "funcdef": "def"}, {"fullname": "spectraxai.utils", "modulename": "spectraxai.utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.continuumRemoval", "modulename": "spectraxai.utils.continuumRemoval", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.continuumRemoval.continuum_removal", "modulename": "spectraxai.utils.continuumRemoval", "qualname": "continuum_removal", "type": "function", "doc": "<p></p>\n", "signature": "(spectrum: numpy.ndarray, wvs: list = [])", "funcdef": "def"}, {"fullname": "spectraxai.utils.datasets", "modulename": "spectraxai.utils.datasets", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.datasets.load_GR_SSL", "modulename": "spectraxai.utils.datasets", "qualname": "load_GR_SSL", "type": "function", "doc": "<p></p>\n", "signature": "(subsampling=20, properties=['OM'])", "funcdef": "def"}, {"fullname": "spectraxai.utils.kennardStone", "modulename": "spectraxai.utils.kennardStone", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.kennardStone.KFold", "modulename": "spectraxai.utils.kennardStone", "qualname": "KFold", "type": "class", "doc": "<p>Base class for KFold, GroupKFold, and StratifiedKFold</p>\n", "bases": "sklearn.model_selection._split._BaseKFold"}, {"fullname": "spectraxai.utils.kennardStone.KFold.__init__", "modulename": "spectraxai.utils.kennardStone", "qualname": "KFold.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, n_splits=5, **kwargs)", "funcdef": "def"}, {"fullname": "spectraxai.utils.kennardStone.KSSplit", "modulename": "spectraxai.utils.kennardStone", "qualname": "KSSplit", "type": "class", "doc": "<p>Base class for ShuffleSplit and StratifiedShuffleSplit</p>\n", "bases": "sklearn.model_selection._split.BaseShuffleSplit"}, {"fullname": "spectraxai.utils.kennardStone.KSSplit.__init__", "modulename": "spectraxai.utils.kennardStone", "qualname": "KSSplit.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, n_splits=10, *, test_size=None, train_size=None)", "funcdef": "def"}, {"fullname": "spectraxai.utils.kennardStone.train_test_split", "modulename": "spectraxai.utils.kennardStone", "qualname": "train_test_split", "type": "function", "doc": "<p></p>\n", "signature": "(*arrays, test_size=None, train_size=None, **kwargs)", "funcdef": "def"}, {"fullname": "spectraxai.utils.modelAssessment", "modulename": "spectraxai.utils.modelAssessment", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.modelAssessment.metrics", "modulename": "spectraxai.utils.modelAssessment", "qualname": "metrics", "type": "function", "doc": "<p></p>\n", "signature": "(y_true, y_pred)", "funcdef": "def"}, {"fullname": "spectraxai.utils.modelAssessment.scatter_plot", "modulename": "spectraxai.utils.modelAssessment", "qualname": "scatter_plot", "type": "function", "doc": "<p></p>\n", "signature": "(y_true, y_pred, ax=None, use_kde=False)", "funcdef": "def"}, {"fullname": "spectraxai.utils.svrParams", "modulename": "spectraxai.utils.svrParams", "type": "module", "doc": "<p></p>\n"}, {"fullname": "spectraxai.utils.svrParams.sigest", "modulename": "spectraxai.utils.svrParams", "qualname": "sigest", "type": "function", "doc": "<p>Estimate SVM gamma based on 0.1 - 0.9 quantile of ||x-x'||^2</p>\n\n<p>Based on sigest function of kernlab. More details may be found here:\nhttps://www.rdocumentation.org/packages/kernlab/\nhttps://rdrr.io/cran/kernlab/src/R/sigest.R</p>\n", "signature": "(x, frac=0.5, scale=True)", "funcdef": "def"}, {"fullname": "spectraxai.utils.svrParams.estimateC", "modulename": "spectraxai.utils.svrParams", "qualname": "estimateC", "type": "function", "doc": "<p>Estimate C based on max{|mean(y)-3\\sigma(y)|, |mean(y)+3\\sigma(y)|}</p>\n\n<p>Rule-of-thumb from dx.doi.org/10.1016/S0893-6080(03)00169-2, Eq. 13</p>\n", "signature": "(y)", "funcdef": "def"}, {"fullname": "spectraxai.utils.svrParams.estimateEpsilon", "modulename": "spectraxai.utils.svrParams", "qualname": "estimateEpsilon", "type": "function", "doc": "<p>Estimate epsilon based on the noise variance</p>\n\n<p>See Equations 17 and 22 of dx.doi.org/10.1016/S0893-6080(03)00169-2</p>\n", "signature": "(X, Y, ndegree=5, half_features=False)", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();